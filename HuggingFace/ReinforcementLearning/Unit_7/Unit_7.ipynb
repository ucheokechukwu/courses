{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOk2zNqulAVEUEsLzW8rS2b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucheokechukwu/courses/blob/main/HuggingFace/ReinforcementLearning/Unit_7/Unit_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('content')\n",
        "import os\n",
        "os.chdir('/content/content/MyDrive/MLOPs_Projects/HuggingFace/ReinforcementLearning_Course/Unit_7')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW90cpGoLewu",
        "outputId": "1d3d31a8-dfe4-4b22-c5df-98b9be2e466c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at content\n",
            "/content/content/MyDrive/MLOPs_Projects/HuggingFace/ReinforcementLearning_Course/Unit_7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "CRxvrdHkTUtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "Nyyd0flQTkX8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6N6sf2ku_ytC",
        "outputId": "984cd38d-05f0-43e5-a8d9-48c8a985619c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/content/MyDrive/MLOPs_Projects/HuggingFace/ReinforcementLearning_Course/Unit_7/ml-agents/ml-agents-envs\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlagents-envs==1.1.0.dev0) (2.2.1)\n",
            "Collecting grpcio<=1.48.2,>=1.11.0 (from mlagents-envs==1.1.0.dev0)\n",
            "  Downloading grpcio-1.48.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from mlagents-envs==1.1.0.dev0) (9.4.0)\n",
            "Collecting protobuf<3.20,>=3.6 (from mlagents-envs==1.1.0.dev0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from mlagents-envs==1.1.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: gym>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from mlagents-envs==1.1.0.dev0) (0.25.2)\n",
            "Collecting pettingzoo==1.15.0 (from mlagents-envs==1.1.0.dev0)\n",
            "  Downloading PettingZoo-1.15.0.tar.gz (756 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.7/756.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mlagents-envs==1.1.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: filelock>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mlagents-envs==1.1.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from grpcio<=1.48.2,>=1.11.0->mlagents-envs==1.1.0.dev0) (1.16.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.21.0->mlagents-envs==1.1.0.dev0) (0.0.8)\n",
            "Building wheels for collected packages: pettingzoo\n",
            "  Building wheel for pettingzoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pettingzoo: filename=PettingZoo-1.15.0-py3-none-any.whl size=875631 sha256=a689cca4bd7ab3452fc4f1668daab30b096ec02f08401fc1dac96df4e1eb99a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/35/ac/76984cb1c12902d190c818d57c43d25c3f9281591a640ccd13\n",
            "Successfully built pettingzoo\n",
            "Installing collected packages: protobuf, grpcio, pettingzoo, mlagents-envs\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.60.0\n",
            "    Uninstalling grpcio-1.60.0:\n",
            "      Successfully uninstalled grpcio-1.60.0\n",
            "  Running setup.py develop for mlagents-envs\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.48.2 mlagents-envs-1.1.0.dev0 pettingzoo-1.15.0 protobuf-3.19.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/content/MyDrive/MLOPs_Projects/HuggingFace/ReinforcementLearning_Course/Unit_7/ml-agents/ml-agents\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: grpcio<=1.48.2,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (1.48.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: mlagents_envs==1.1.0.dev0 in ./ml-agents-envs (from mlagents==1.1.0.dev0) (1.1.0.dev0)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: Pillow>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.6 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (3.19.6)\n",
            "Requirement already satisfied: pyyaml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (6.0.1)\n",
            "Collecting torch>=2.1.1 (from mlagents==1.1.0.dev0)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.14 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (2.15.1)\n",
            "Requirement already satisfied: six>=1.16 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (23.2.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.14 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.1.0.dev0) (0.20.3)\n",
            "Collecting onnx==1.12.0 (from mlagents==1.1.0.dev0)\n",
            "  Downloading onnx-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cattrs<1.7,>=1.1.0 (from mlagents==1.1.0.dev0)\n",
            "  Downloading cattrs-1.5.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.1.0.dev0->mlagents==1.1.0.dev0) (2.2.1)\n",
            "Requirement already satisfied: gym>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.1.0.dev0->mlagents==1.1.0.dev0) (0.25.2)\n",
            "Requirement already satisfied: pettingzoo==1.15.0 in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.1.0.dev0->mlagents==1.1.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: filelock>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.1.0.dev0->mlagents==1.1.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.12.0->mlagents==1.1.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.14->mlagents==1.1.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.14->mlagents==1.1.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.14->mlagents==1.1.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.14->mlagents==1.1.0.dev0) (23.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14->mlagents==1.1.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14->mlagents==1.1.0.dev0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14->mlagents==1.1.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14->mlagents==1.1.0.dev0) (3.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14->mlagents==1.1.0.dev0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14->mlagents==1.1.0.dev0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14->mlagents==1.1.0.dev0) (3.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->mlagents==1.1.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->mlagents==1.1.0.dev0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->mlagents==1.1.0.dev0) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->mlagents==1.1.0.dev0) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.1->mlagents==1.1.0.dev0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14->mlagents==1.1.0.dev0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14->mlagents==1.1.0.dev0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14->mlagents==1.1.0.dev0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.14->mlagents==1.1.0.dev0) (1.3.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.21.0->mlagents_envs==1.1.0.dev0->mlagents==1.1.0.dev0) (0.0.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.14->mlagents==1.1.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.14->mlagents==1.1.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.14->mlagents==1.1.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.14->mlagents==1.1.0.dev0) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.14->mlagents==1.1.0.dev0) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.1->mlagents==1.1.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.14->mlagents==1.1.0.dev0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.14->mlagents==1.1.0.dev0) (3.2.2)\n",
            "Installing collected packages: onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, cattrs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, mlagents\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Running setup.py develop for mlagents\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cattrs-1.5.0 mlagents-1.1.0.dev0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 onnx-1.12.0 torch-2.1.2\n",
            "CODE_OF_CONDUCT.md\t\tLICENSE.md\t\t       Project\n",
            "colab\t\t\t\tlocalized_docs\t\t       protobuf-definitions\n",
            "colab_requirements.txt\t\tmarkdown-link-check.fast.json  pytest.ini\n",
            "com.unity.ml-agents\t\tmarkdown-link-check.full.json  setup.cfg\n",
            "com.unity.ml-agents.extensions\tmkdocs.yml\t\t       SURVEY.md\n",
            "config\t\t\t\tml-agents\t\t       test_constraints_version.txt\n",
            "conftest.py\t\t\tml-agents-envs\t\t       test_requirements.txt\n",
            "DevProject\t\t\tml-agents-plugin-examples      training-envs-executables\n",
            "Dockerfile\t\t\tml-agents-trainer-plugin       unity-volume\n",
            "docs\t\t\t\tPerformanceProject\t       utils\n"
          ]
        }
      ],
      "source": [
        "# !git clone --depth 1  https://github.com/Unity-Technologies/ml-agents\n",
        "os.chdir ('ml-agents')\n",
        "!pip install -e ./ml-agents-envs\n",
        "!pip install -e ./ml-agents\n",
        "\n",
        "!mkdir training-envs-executables\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rich import print, inspect, pretty\n",
        "pretty.install()"
      ],
      "metadata": {
        "id": "ES8tsDVYP0sG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and move environment"
      ],
      "metadata": {
        "id": "SlDqrqGzTX9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ../SoccerTwos.zip ./training-envs-executables/SoccerTwos.zip\n",
        "!unzip ./training-envs-executables/SoccerTwos.zip -d ./training-envs-executables\n",
        "!rm ./training-envs-executables/SoccerTwos.zip\n",
        "!ls ./training-envs-executables\n",
        "!chmod -R 755 \"/content/content/MyDrive/MLOPs_Projects/HuggingFace/ReinforcementLearning_Course/Unit_7/ml-agents/training-envs-executables/SoccerTwos.x86_64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9j1R0xlAF2a",
        "outputId": "c6794dd9-f9d6-48c2-d843-7b2f10be10d2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SoccerTwos_BurstDebugInformation_DoNotShip  SoccerTwos_Data  SoccerTwos.x86_64\tUnityPlayer.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "f6VCWnX3TNDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config File"
      ],
      "metadata": {
        "id": "o1LqHIDnTQgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./config/poca/SoccerTwos.yaml\n",
        "\n",
        "behaviors:\n",
        "  SoccerTwos:\n",
        "    trainer_type: poca\n",
        "    hyperparameters:\n",
        "      batch_size: 2048\n",
        "      buffer_size: 20480\n",
        "      learning_rate: 0.0003\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "      learning_rate_schedule: constant\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 512\n",
        "      num_layers: 2\n",
        "      vis_encode_type: simple\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "    keep_checkpoints: 5\n",
        "    max_steps: 5000000\n",
        "    time_horizon: 1000\n",
        "    summary_freq: 10000\n",
        "    self_play:\n",
        "      save_steps: 50000\n",
        "      team_change: 200000\n",
        "      swap_steps: 2000\n",
        "      window: 10\n",
        "      play_against_latest_model_ratio: 0.5\n",
        "      initial_elo: 1200.0"
      ],
      "metadata": {
        "id": "voPk0662AfHZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ml_agents` training (5M time steps)"
      ],
      "metadata": {
        "id": "_Fe0OOALTprO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn ./config/poca/SoccerTwos.yaml --env=./training-envs-executables/SoccerTwos.x86_64 --run-id=\"SoccerTwos\" --no-graphics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1AZD5GnRplk",
        "outputId": "1b29c535-3e04-4fa6-ed26-8c8eb658b0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.1.0.dev0,\n",
            "  ml-agents-envs: 1.1.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.1.2+cu121\n",
            "[INFO] Connected to Unity environment with package version 2.3.0-exp.3 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SoccerTwos?team=1\n",
            "[INFO] Connected new brain: SoccerTwos?team=0\n",
            "[INFO] Hyperparameters for behavior name SoccerTwos: \n",
            "\ttrainer_type:\tpoca\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tconstant\n",
            "\t  beta_schedule:\tconstant\n",
            "\t  epsilon_schedule:\tconstant\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t50000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\t\n",
            "\t  save_steps:\t50000\n",
            "\t  team_change:\t200000\n",
            "\t  swap_steps:\t2000\n",
            "\t  window:\t10\n",
            "\t  play_against_latest_model_ratio:\t0.5\n",
            "\t  initial_elo:\t1200.0\n",
            "\tbehavioral_cloning:\tNone\n",
            "/content/content/MyDrive/MLOPs_Projects/HuggingFace/ReinforcementLearning_Course/Unit_7/ml-agents/ml-agents/mlagents/trainers/torch_entities/utils.py:289: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
            "  torch.nn.functional.one_hot(_act.T, action_size[i]).float()\n",
            "[INFO] SoccerTwos. Step: 10000. Time Elapsed: 39.912 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 20000. Time Elapsed: 69.438 s. Mean Reward: 0.000. Mean Group Reward: -0.136. Training. ELO: 1199.503.\n",
            "[INFO] SoccerTwos. Step: 30000. Time Elapsed: 70.273 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 40000. Time Elapsed: 110.690 s. Mean Reward: 0.000. Mean Group Reward: -0.230. Training. ELO: 1200.670.\n",
            "[INFO] SoccerTwos. Step: 50000. Time Elapsed: 128.459 s. Mean Reward: 0.000. Mean Group Reward: -0.429. Training. ELO: 1200.000.\n",
            "[INFO] SoccerTwos. Step: 60000. Time Elapsed: 160.359 s. Mean Reward: 0.000. Mean Group Reward: -0.139. Training. ELO: 1198.703.\n",
            "[INFO] SoccerTwos. Step: 70000. Time Elapsed: 173.982 s. Mean Reward: 0.000. Mean Group Reward: -0.429. Training. ELO: 1197.758.\n",
            "[INFO] SoccerTwos. Step: 80000. Time Elapsed: 199.683 s. Mean Reward: 0.000. Mean Group Reward: -0.283. Training. ELO: 1197.016.\n",
            "[INFO] SoccerTwos. Step: 90000. Time Elapsed: 222.860 s. Mean Reward: 0.000. Mean Group Reward: -0.089. Training. ELO: 1197.115.\n",
            "[INFO] SoccerTwos. Step: 100000. Time Elapsed: 247.292 s. Mean Reward: 0.000. Mean Group Reward: -0.194. Training. ELO: 1195.228.\n",
            "[INFO] SoccerTwos. Step: 110000. Time Elapsed: 268.979 s. Mean Reward: 0.000. Mean Group Reward: -0.029. Training. ELO: 1194.085.\n",
            "[INFO] SoccerTwos. Step: 120000. Time Elapsed: 299.245 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 130000. Time Elapsed: 314.380 s. Mean Reward: 0.000. Mean Group Reward: -0.333. Training. ELO: 1193.768.\n",
            "[INFO] SoccerTwos. Step: 140000. Time Elapsed: 342.292 s. Mean Reward: 0.000. Mean Group Reward: 0.136. Training. ELO: 1194.882.\n",
            "[INFO] SoccerTwos. Step: 150000. Time Elapsed: 365.514 s. Mean Reward: 0.000. Mean Group Reward: 0.239. Training. ELO: 1195.138.\n",
            "[INFO] SoccerTwos. Step: 160000. Time Elapsed: 391.204 s. Mean Reward: 0.000. Mean Group Reward: -0.196. Training. ELO: 1194.175.\n",
            "[INFO] SoccerTwos. Step: 170000. Time Elapsed: 414.305 s. Mean Reward: 0.000. Mean Group Reward: -0.265. Training. ELO: 1194.133.\n",
            "[INFO] SoccerTwos. Step: 180000. Time Elapsed: 433.483 s. Mean Reward: 0.000. Mean Group Reward: 0.075. Training. ELO: 1194.133.\n",
            "[INFO] SoccerTwos. Step: 190000. Time Elapsed: 461.842 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 200000. Time Elapsed: 475.211 s. Mean Reward: 0.000. Mean Group Reward: 0.059. Training. ELO: 1194.882.\n",
            "[INFO] SoccerTwos. Step: 210000. Time Elapsed: 516.595 s. Mean Reward: 0.000. Mean Group Reward: -0.222. Training. ELO: 1193.879.\n",
            "[INFO] SoccerTwos. Step: 220000. Time Elapsed: 541.414 s. Mean Reward: 0.000. Mean Group Reward: 0.140. Training. ELO: 1194.390.\n",
            "[INFO] SoccerTwos. Step: 230000. Time Elapsed: 575.934 s. Mean Reward: 0.000. Mean Group Reward: -0.081. Training. ELO: 1195.765.\n",
            "[INFO] SoccerTwos. Step: 240000. Time Elapsed: 584.632 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 250000. Time Elapsed: 615.076 s. Mean Reward: 0.000. Mean Group Reward: -0.081. Training. ELO: 1195.684.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push to Huggingface Hub"
      ],
      "metadata": {
        "id": "_Czds1JeTuTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "Jgv_Mce4SRjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./results"
      ],
      "metadata": {
        "id": "pffd1iKoUg2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf --run-id=\"SoccerTwos\" --local-dir=\"./results/SoccerTwos\" --repo-id=\"ucheokechukwu/poca-SoccerTwos\" --commit-message=\"First Commit\""
      ],
      "metadata": {
        "id": "yDpI-V2WUTGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}